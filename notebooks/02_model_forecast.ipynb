{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling + Forecast\n",
    "Compare baseline vs improved; export forecasts and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9c0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "DATA_DIR = Path(\"Data\")\n",
    "\n",
    "# Expected columns in operations_daily: date, site_id, units_produced, power_kwh, downtime_minutes (optional)\n",
    "# Expected columns in site_meta: site_id, region, capacity, ...\n",
    "\n",
    "def read_operations(path: Optional[str] = None, data_dir: Path = DATA_DIR) -> pd.DataFrame:\n",
    "    REQUIRED_COLS = {\"date\", \"site_id\", \"units_produced\", \"power_kwh\"}\n",
    "\n",
    "    def _load(p: Path) -> pd.DataFrame:\n",
    "        df = pd.read_csv(p, parse_dates=[\"date\"])  # type: ignore[arg-type]\n",
    "        if not REQUIRED_COLS.issubset(df.columns):\n",
    "            raise ValueError(f\"{p.name} missing required columns: {REQUIRED_COLS - set(df.columns)}\")\n",
    "        return df.sort_values([\"site_id\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "    if path:\n",
    "        return _load(Path(path))\n",
    "\n",
    "    candidates = sorted(data_dir.glob(\"operations_daily_*.csv\"))\n",
    "    if candidates:\n",
    "        def _days(p: Path) -> int:\n",
    "            name = p.stem\n",
    "            token = name.split(\"_\")[-1]\n",
    "            return int(token[:-1]) if token.endswith(\"d\") and token[:-1].isdigit() else 0\n",
    "        chosen = max(candidates, key=_days)\n",
    "        return _load(chosen)\n",
    "\n",
    "    fallback = data_dir / \"operations_daily.csv\"\n",
    "    if fallback.exists():\n",
    "        return _load(fallback)\n",
    "\n",
    "    raise FileNotFoundError(\"No operations_daily CSV found in Data/\")\n",
    "\n",
    "def read_site_meta(path: Optional[str] = None) -> pd.DataFrame:\n",
    "    p = Path(path) if path else DATA_DIR / \"site_meta.csv\"\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"site_meta not found at {p}\")\n",
    "    df = pd.read_csv(p)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db77d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature engineering utilities\n",
    "# - Calendar features\n",
    "# - Rolling means as baselines\n",
    "# - Site metadata join\n",
    "\n",
    "def add_calendar_features(df: pd.DataFrame, date_col: str = \"date\") -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d[date_col] = pd.to_datetime(d[date_col])\n",
    "    d[\"dow\"] = d[date_col].dt.dayofweek  # 0=Mon\n",
    "    d[\"dom\"] = d[date_col].dt.day\n",
    "    d[\"month\"] = d[date_col].dt.month\n",
    "    d[\"week\"] = d[date_col].dt.isocalendar().week.astype(int)\n",
    "    d[\"is_weekend\"] = (d[\"dow\"] >= 5).astype(int)\n",
    "    return d\n",
    "\n",
    "\n",
    "def add_rolling_features(df: pd.DataFrame,\n",
    "                         by: list[str] = [\"site_id\"],\n",
    "                         date_col: str = \"date\",\n",
    "                         targets: list[str] = [\"units_produced\", \"power_kwh\"],\n",
    "                         windows: list[int] = [3, 7, 14, 28]) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d = d.sort_values(by + [date_col])\n",
    "    for tgt in targets:\n",
    "        if tgt not in d.columns:\n",
    "            continue\n",
    "        for w in windows:\n",
    "            d[f\"{tgt}_rollmean_{w}\"] = (\n",
    "                d.groupby(by)[tgt]\n",
    "                .transform(lambda s: s.rolling(w, min_periods=max(1, w//2)).mean())\n",
    "            )\n",
    "            d[f\"{tgt}_rollstd_{w}\"] = (\n",
    "                d.groupby(by)[tgt]\n",
    "                .transform(lambda s: s.rolling(w, min_periods=max(1, w//2)).std())\n",
    "            )\n",
    "    return d\n",
    "\n",
    "\n",
    "def join_site_meta(ops: pd.DataFrame, site_meta: pd.DataFrame) -> pd.DataFrame:\n",
    "    meta = site_meta.copy()\n",
    "\n",
    "    # Normalize join key dtype\n",
    "    ops[\"site_id\"] = ops[\"site_id\"].astype(str)\n",
    "    meta[\"site_id\"] = meta[\"site_id\"].astype(str)\n",
    "\n",
    "    # Encode categoricals except join key\n",
    "    for c in meta.select_dtypes(include=[\"object\"]).columns:\n",
    "        if c != \"site_id\":\n",
    "            try:\n",
    "                meta[c] = meta[c].astype(\"category\").cat.codes\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return ops.merge(meta, on=\"site_id\", how=\"left\")\n",
    "\n",
    "\n",
    "def prepare_features(ops: pd.DataFrame, site_meta: pd.DataFrame | None = None) -> pd.DataFrame:\n",
    "    d = add_calendar_features(ops)\n",
    "    d = add_rolling_features(d)\n",
    "    if site_meta is not None:\n",
    "        d = join_site_meta(d, site_meta)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f45d2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Optional: you can switch to XGBoost/LightGBM if installed\n",
    "try:\n",
    "    from xgboost import XGBRegressor  # type: ignore\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "HORIZON = 14\n",
    "TARGETS = [\"units_produced\", \"power_kwh\"]\n",
    "\n",
    "\n",
    "def seasonal_naive_forecast(history: pd.Series, season: int = 7, horizon: int = HORIZON) -> np.ndarray:\n",
    "    if len(history) == 0:\n",
    "        return np.zeros(horizon)\n",
    "    if len(history) < season:\n",
    "        last = history.iloc[-1]\n",
    "        return np.repeat(last, horizon)\n",
    "    template = history.iloc[-season:]\n",
    "    reps = int(np.ceil(horizon / season))\n",
    "    fc = np.tile(template.values, reps)[:horizon]\n",
    "    return fc\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ForecastResult:\n",
    "    site_id: str | int\n",
    "    target: str\n",
    "    dates: List[pd.Timestamp]\n",
    "    y_true: List[float]\n",
    "    y_hat_baseline: List[float]\n",
    "    y_hat_model: List[float]\n",
    "    mae_baseline: float\n",
    "    mae_model: float\n",
    "    mape_baseline: float\n",
    "    mape_model: float\n",
    "\n",
    "\n",
    "def _mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    denom = np.clip(np.abs(y_true), 1e-6, None)\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / denom)))\n",
    "\n",
    "\n",
    "def train_improved_model(train_df: pd.DataFrame, feature_cols: List[str], target: str):\n",
    "    X = train_df[feature_cols].values\n",
    "    y = train_df[target].values\n",
    "    if HAS_XGB:\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "        )\n",
    "    else:\n",
    "        model = GradientBoostingRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def rolling_backtest_site(df_site: pd.DataFrame, target: str, feature_cols: List[str], horizon: int = HORIZON,\n",
    "                          min_train: int = 60) -> Tuple[ForecastResult, pd.DataFrame]:\n",
    "    d = df_site.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    # Train/validation split using expanding window with last horizon as test\n",
    "    if len(d) < (min_train + horizon):\n",
    "        # Fallback: train on all but last horizon\n",
    "        split = max(1, len(d) - horizon)\n",
    "    else:\n",
    "        split = len(d) - horizon\n",
    "\n",
    "    train = d.iloc[:split].copy()\n",
    "    test = d.iloc[split:].copy()\n",
    "\n",
    "    # Baseline\n",
    "    base_fc = seasonal_naive_forecast(train[target], season=7, horizon=len(test))\n",
    "\n",
    "    # Improved model\n",
    "    model = train_improved_model(train, feature_cols, target)\n",
    "    y_hat_model = model.predict(test[feature_cols].values)\n",
    "\n",
    "    mae_baseline = float(mean_absolute_error(test[target].values, base_fc))\n",
    "    mae_model = float(mean_absolute_error(test[target].values, y_hat_model))\n",
    "    mape_baseline = _mape(test[target].values, base_fc)\n",
    "    mape_model = _mape(test[target].values, y_hat_model)\n",
    "\n",
    "    res = ForecastResult(\n",
    "        site_id=d.loc[0, \"site_id\"],\n",
    "        target=target,\n",
    "        dates=list(pd.to_datetime(test[\"date\"])),\n",
    "        y_true=list(test[target].values.astype(float)),\n",
    "        y_hat_baseline=list(base_fc.astype(float)),\n",
    "        y_hat_model=list(y_hat_model.astype(float)),\n",
    "        mae_baseline=mae_baseline,\n",
    "        mae_model=mae_model,\n",
    "        mape_baseline=mape_baseline,\n",
    "        mape_model=mape_model,\n",
    "    )\n",
    "\n",
    "    # Produce next-horizon forecast using all data\n",
    "    final_model = train_improved_model(d, feature_cols, target)\n",
    "    # Use last known row features to roll forward naively for horizon days using calendar features only\n",
    "    future_dates = pd.date_range(d[\"date\"].max() + pd.Timedelta(days=1), periods=horizon, freq=\"D\")\n",
    "    # Recreate calendar-only features; rolling features won't be available out-of-the-box\n",
    "    fut = pd.DataFrame({\"date\": future_dates, \"site_id\": d.loc[0, \"site_id\"]})\n",
    "    fut = add_calendar_features(fut)\n",
    "    # Fill missing rolling/meta features with last known values per column\n",
    "    for c in feature_cols:\n",
    "        if c not in fut.columns:\n",
    "            last_val = d[c].iloc[-1] if c in d.columns else 0.0\n",
    "            fut[c] = last_val\n",
    "    fut = fut[feature_cols]\n",
    "    future_pred = final_model.predict(fut.values)\n",
    "\n",
    "    test[\"y_hat_baseline\"] = base_fc\n",
    "    test[\"y_hat_model\"] = y_hat_model\n",
    "\n",
    "    return res, pd.DataFrame({\n",
    "        \"site_id\": d.loc[0, \"site_id\"],\n",
    "        \"date\": future_dates,\n",
    "        \"target\": target,\n",
    "        \"y_hat\": future_pred,\n",
    "    })\n",
    "\n",
    "\n",
    "def run_modeling(df: pd.DataFrame, feature_cols: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    forecasts = []\n",
    "    metrics = []\n",
    "    for site_id, g in df.groupby(\"site_id\"):\n",
    "        for tgt in TARGETS:\n",
    "            if tgt not in g.columns:\n",
    "                continue\n",
    "            res, fut = rolling_backtest_site(g, tgt, feature_cols)\n",
    "            forecasts.append(fut)\n",
    "            metrics.append({\n",
    "                \"site_id\": site_id,\n",
    "                \"target\": tgt,\n",
    "                \"mae_baseline\": res.mae_baseline,\n",
    "                \"mae_model\": res.mae_model,\n",
    "                \"mape_baseline\": res.mape_baseline,\n",
    "                \"mape_model\": res.mape_model,\n",
    "            })\n",
    "    return pd.concat(forecasts, ignore_index=True), pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "site_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mae_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mae_model",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mape_baseline",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mape_model",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4b403436-167e-4811-8013-90d112005b8d",
       "rows": [
        [
         "0",
         "S1",
         "units_produced",
         "82.5",
         "69.13261195591518",
         "0.06363136609043588",
         "0.054217893872783904"
        ],
        [
         "1",
         "S1",
         "power_kwh",
         "561.0714285714286",
         "296.94185965401783",
         "0.11290606992691633",
         "0.06365508752319404"
        ],
        [
         "2",
         "S2",
         "units_produced",
         "152.5",
         "78.52060372488839",
         "0.10008309778524183",
         "0.050411655711175805"
        ],
        [
         "3",
         "S2",
         "power_kwh",
         "543.0",
         "309.89969308035717",
         "0.10951079075041185",
         "0.06255455536909042"
        ],
        [
         "4",
         "S3",
         "units_produced",
         "148.21428571428572",
         "56.09094674246652",
         "0.13040363809809488",
         "0.05018976819625021"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>target</th>\n",
       "      <th>mae_baseline</th>\n",
       "      <th>mae_model</th>\n",
       "      <th>mape_baseline</th>\n",
       "      <th>mape_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1</td>\n",
       "      <td>units_produced</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>69.132612</td>\n",
       "      <td>0.063631</td>\n",
       "      <td>0.054218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1</td>\n",
       "      <td>power_kwh</td>\n",
       "      <td>561.071429</td>\n",
       "      <td>296.941860</td>\n",
       "      <td>0.112906</td>\n",
       "      <td>0.063655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2</td>\n",
       "      <td>units_produced</td>\n",
       "      <td>152.500000</td>\n",
       "      <td>78.520604</td>\n",
       "      <td>0.100083</td>\n",
       "      <td>0.050412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2</td>\n",
       "      <td>power_kwh</td>\n",
       "      <td>543.000000</td>\n",
       "      <td>309.899693</td>\n",
       "      <td>0.109511</td>\n",
       "      <td>0.062555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S3</td>\n",
       "      <td>units_produced</td>\n",
       "      <td>148.214286</td>\n",
       "      <td>56.090947</td>\n",
       "      <td>0.130404</td>\n",
       "      <td>0.050190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site_id          target  mae_baseline   mae_model  mape_baseline  mape_model\n",
       "0      S1  units_produced     82.500000   69.132612       0.063631    0.054218\n",
       "1      S1       power_kwh    561.071429  296.941860       0.112906    0.063655\n",
       "2      S2  units_produced    152.500000   78.520604       0.100083    0.050412\n",
       "3      S2       power_kwh    543.000000  309.899693       0.109511    0.062555\n",
       "4      S3  units_produced    148.214286   56.090947       0.130404    0.050190"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ops = read_operations()\n",
    "meta = read_site_meta()\n",
    "X = prepare_features(ops, meta)\n",
    "feature_cols = [c for c in X.columns if c not in {'date','site_id','units_produced','power_kwh'}]\n",
    "forecasts, metrics = run_modeling(X, feature_cols)\n",
    "\n",
    "forecasts_units = forecasts[forecasts['target']=='units_produced'].copy()\n",
    "forecasts_power = forecasts[forecasts['target']=='power_kwh'].copy()\n",
    "forecasts_units.to_csv('outputs/forecast_units.csv', index=False)\n",
    "forecasts_power.to_csv('outputs/forecast_power.csv', index=False)\n",
    "metrics.to_csv('outputs/model_metrics.csv', index=False)\n",
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a188ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
